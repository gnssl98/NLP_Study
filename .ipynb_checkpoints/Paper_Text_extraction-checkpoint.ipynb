{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53480679-5cd8-4edf-a5e2-797ecb8f42e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pypdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpypdf\u001b[39;00m  \u001b[38;5;66;03m# âœ… PyPDF ëŒ€ì‹  pypdf ì‚¬ìš©!\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_pdf_text\u001b[39m(pdf_path):\n\u001b[0;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pypdf'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pypdf  # âœ… PyPDF ëŒ€ì‹  pypdf ì‚¬ìš©!\n",
    "\n",
    "def load_pdf_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = pypdf.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# ë…¼ë¬¸ PDF íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "pdf_path = \"D:\\ë‹¤ìš´ë¡œë“œ\\A Genetic Algorithm for Communiry Detection in Social Networks.pdf\"\n",
    "text = load_pdf_text(pdf_path)\n",
    "\n",
    "# ì¶œë ¥ í™•ì¸\n",
    "print(f\"ğŸ“„ ë…¼ë¬¸ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ (ì¼ë¶€):\\n{text[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2970a45-ff70-4cdd-8647-7c5ad93b46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ë¬´ë£Œ ì„ë² ë”© ëª¨ë¸ (Hugging Face)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "sentences = text.split(\"\\n\")\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "# FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ í™•ì¸\n",
    "print(f\"ğŸ” ì €ì¥ëœ ë¬¸ì¥ ê°œìˆ˜: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "295cf296-47bf-42a6-bf74-cbcafbd6d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì €ì¥ëœ ë¬¸ì¥ ê°œìˆ˜: 1265\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ë¬´ë£Œ ì„ë² ë”© ëª¨ë¸ (Hugging Face)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "sentences = text.split(\"\\n\")\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "# FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ í™•ì¸\n",
    "print(f\"ğŸ” ì €ì¥ëœ ë¬¸ì¥ ê°œìˆ˜: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3774a7-b5ba-44d5-8581-b448e27e2bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©:\n",
      "To assess the performance of TSSAN, we conducted\n",
      "K LN\n",
      "TSSAN (supervised). Nevertheless, in terms of training\n"
     ]
    }
   ],
   "source": [
    "def search_relevant_text(query, top_k=3):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    distances, indices = index.search(np.array(query_embedding), top_k)\n",
    "    \n",
    "    results = [sentences[idx] for idx in indices[0]]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥\n",
    "query = \"ì´ ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë¬´ì—‡ì¸ê°€?\"\n",
    "retrieved_text = search_relevant_text(query)\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©:\\n{retrieved_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35f9c0-f9f6-4d39-866a-1903d7c50834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2c582d8bfb414f84913dcd8e0f7283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dcb740b44b4e6a98f35d6b85aa4521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a10f61fe8384ce48cb92fb20d38cb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8f8f9e92004da39845e2082e6e6a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae6eda4a6cb4712a034bf6c99216238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab771d93e27446f2819366a965029616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# âœ… ë¬´ë£Œ ê³µê°œ LLM ëª¨ë¸ ì‚¬ìš© (Gated Repo í•„ìš” ì—†ìŒ)\n",
    "qa_pipeline = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\")\n",
    "\n",
    "def generate_answer(query, context):\n",
    "    prompt = f\"ì§ˆë¬¸: {query}\\n\\nê´€ë ¨ ì •ë³´: {context}\\n\\në‹µë³€:\"\n",
    "    response = qa_pipeline(prompt, max_length=200, do_sample=True)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "query = \"ì´ ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë¬´ì—‡ì¸ê°€?\"\n",
    "context = \"ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ í¬í•¨í•œ ê²€ìƒ‰ ê²°ê³¼\"\n",
    "answer = generate_answer(query, context)\n",
    "\n",
    "print(f\"ğŸ“ ì§ˆë¬¸: {query}\\nğŸ’¡ ë‹µë³€: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e1182-0d7e-4aa0-944e-a07b1279c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    prompt = f\"ë‹¤ìŒ ë…¼ë¬¸ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜:\\n{text[:2000]}\"  # ê¸¸ì´ ì œí•œ (2000ì)\n",
    "    response = qa_pipeline(prompt, max_length=300, do_sample=True)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "summary = summarize_text(text)\n",
    "\n",
    "print(f\"ğŸ“„ ë…¼ë¬¸ ìš”ì•½:\\n{summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e73648-d217-4fa1-8686-64e60a3e2ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614e6db-d8f3-44e3-a1e3-906b4b537e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
