{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f602cf3-d1f4-4760-a5b4-1fd818d619b5",
   "metadata": {},
   "source": [
    "## NSMC(Naver Sentiment Movie Corpis\n",
    "네이버 영화 리뷰 말뭉치<br>\n",
    "from Korpora import Korpora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae3e3b-b4a8-48b4-89e7-009c4518d74f",
   "metadata": {},
   "source": [
    " * 사용하는 모델: beomi/kcbert-base\n",
    " *  모델 구조: BertForSequenceClassification (BERT 모델을 감성 분석용 분류기로 변환)\n",
    " * 사전 학습된 데이터: 한국어 데이터(Korean)로 사전 학습된 KcBERT 모델\n",
    " * 추가 학습하는 데이터: NSMC(네이버 영화 리뷰 감성 분석) 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df41cf5-f535-42ce-9704-b8e94237ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0\n",
      "MPS 지원 여부: True\n",
      "MPS 사용 가능: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"MPS 지원 여부:\", torch.backends.mps.is_available())  # True여야 정상 작동\n",
    "print(\"MPS 사용 가능:\", torch.backends.mps.is_built())  # True여야 정상 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e39235ec-8fa9-4cc6-b753-a7900c6770ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 디바이스: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"사용할 디바이스:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a7b7f4-1d19-4c32-a8fd-faf7d9b07856",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "토큰화 수행 프로그램<br>\n",
    "kcbert-base 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f43528-f66b-45cd-8450-29785e6f840b",
   "metadata": {},
   "source": [
    "# Pytorch's Data Loader\n",
    "\n",
    "* 파이토치로 딥러닝 모델을 만들려면 반드시 정의해야 한다.\n",
    "* 데이터를 배치(batch)단위로 모델에 밀어 넣어주는 역할\n",
    "* 전체 데이터 가운데 일부 인스턴스를 뽑아 배치를 구성\n",
    "* 데이터셋은 데이터 로더의 구성 요소 중 하나\n",
    "* 데이터셋은 여러 인스턴스를 보유\n",
    "\n",
    "데이터 로더 > 데이터셋 > 인스턴스\n",
    "\n",
    "* batch는 그 모양이 고정적이어야 할 때가 많다. -> 문장들의 토큰(input_ids) 개수가 같아야 한다.\n",
    "\n",
    "그래서 batch의 shape을 동일하게 만들어 주는 과정을 collate라고 한다.\n",
    "\n",
    "### Collate\n",
    "* list -> pytorch의 tensor로 변환\n",
    "* batch size 통일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2124a-ca1b-4ca5-bf3a-84a65647421f",
   "metadata": {},
   "source": [
    "### Pytorch Lightning\n",
    "https://minjoo-happy-blog.tistory.com/140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b15a9bb-9f11-4e58-8021-404bdd86ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 KcBERT 모델 성능 평가 중...\n",
      "📊 정확도 (Accuracy): 49.43%\n",
      "📊 상세 평가 결과:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        부정 😡       0.49      0.59      0.54     24826\n",
      "        긍정 😊       0.50      0.40      0.44     25171\n",
      "\n",
      "    accuracy                           0.49     49997\n",
      "   macro avg       0.49      0.49      0.49     49997\n",
      "weighted avg       0.49      0.49      0.49     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from Korpora import Korpora\n",
    "\n",
    "# KcBERT 모델 및 토크나이저 로드\n",
    "MODEL_NAME = \"beomi/kcbert-base\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "# GPU(MPS) 또는 CPU 설정\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드\n",
    "\n",
    "# NSMC 데이터 다운로드 및 로드\n",
    "data_dir = \"./data/nsmc\"\n",
    "test_file = f\"{data_dir}/ratings_test.txt\"\n",
    "\n",
    "# 데이터가 없으면 자동 다운로드\n",
    "if not os.path.exists(test_file):\n",
    "    Korpora.fetch(\"nsmc\", root_dir=data_dir)\n",
    "\n",
    "# NSMC 테스트 데이터 불러오기\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\").dropna()\n",
    "\n",
    "# NSMC 데이터셋을 PyTorch Dataset 형식으로 변환\n",
    "class NsmcDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            df[\"document\"].astype(str).tolist(),\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.labels = torch.tensor(df[\"label\"].tolist(), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"label\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "# 데이터셋 및 DataLoader 생성\n",
    "test_dataset = NsmcDataset(test_df, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 모델 평가 함수 정의\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 성능 평가 결과 출력\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"📊 정확도 (Accuracy): {acc * 100:.2f}%\")\n",
    "    print(\"📊 상세 평가 결과:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"부정 😡\", \"긍정 😊\"]))\n",
    "\n",
    "# 모델 성능 평가 실행\n",
    "print(\"🔍 KcBERT 모델 성능 평가 중...\")\n",
    "evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b7fd51d-b7e8-49a4-b20c-d6eca1e38012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋 평가 중...\n",
      "모델 정확도: 51.10%\n",
      "입력 문장: 이 영화는 정말 최고였어!\n",
      "예측 결과: 부정 😡 (확률: 51.04%)\n",
      "\n",
      "입력 문장: 완전 최악이야, 시간 낭비했어.\n",
      "예측 결과: 부정 😡 (확률: 52.02%)\n",
      "\n",
      "입력 문장: 그냥 그랬어. 별로 감흥이 없었어.\n",
      "예측 결과: 부정 😡 (확률: 57.55%)\n",
      "\n",
      "입력 문장: 배우 연기가 너무 훌륭했어!\n",
      "예측 결과: 부정 😡 (확률: 52.94%)\n",
      "\n",
      "입력 문장: 스토리가 너무 지루했어.\n",
      "예측 결과: 부정 😡 (확률: 52.74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass  \n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "@dataclass\n",
    "class ClassificationTrainArguments:\n",
    "    pretrained_model_name: str\n",
    "    downstream_corpus_name: str\n",
    "    downstream_corpus_root_dir: str\n",
    "    downstream_model_dir: str\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "\n",
    "args = ClassificationTrainArguments(\n",
    "    pretrained_model_name=\"beomi/kcbert-base\",  # KC-BERT 사용\n",
    "    downstream_corpus_name=\"nsmc\",\n",
    "    downstream_corpus_root_dir=\"./data\",\n",
    "    downstream_model_dir=\"./model\",\n",
    "    learning_rate=5e-5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# MPS(GPU) 자동 감지 및 설정\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "\n",
    "# NSMC 데이터 다운로드\n",
    "data_dir = f\"{args.downstream_corpus_root_dir}/{args.downstream_corpus_name}\"\n",
    "train_file = f\"{data_dir}/ratings_train.txt\"\n",
    "test_file = f\"{data_dir}/ratings_test.txt\"\n",
    "\n",
    "if not os.path.exists(train_file):\n",
    "    Korpora.fetch(args.downstream_corpus_name, root_dir=data_dir)\n",
    "\n",
    "# 모델 및 토크나이저 로드 (순서 수정)\n",
    "tokenizer = BertTokenizer.from_pretrained(args.pretrained_model_name, do_lower_case=False)\n",
    "\n",
    "pretrained_model_config = BertConfig.from_pretrained(args.pretrained_model_name, num_labels=2)\n",
    "model = BertForSequenceClassification.from_pretrained(args.pretrained_model_name, config=pretrained_model_config)\n",
    "\n",
    "# 모델을 디바이스로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 데이터 불러오기 (샘플링 적용)\n",
    "train_df = pd.read_csv(train_file, sep=\"\\t\").dropna().sample(5000)  # 일부 샘플 사용\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\").dropna().sample(1000)\n",
    "\n",
    "# NSMC 데이터셋 클래스\n",
    "class NsmcDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            df[\"document\"].astype(str).tolist(),\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.labels = torch.tensor(df[\"label\"].tolist(), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"label\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "# 데이터셋 및 DataLoader 생성\n",
    "train_dataset = NsmcDataset(train_df, tokenizer)\n",
    "test_dataset = NsmcDataset(test_df, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# 감성 분석 모델 정의 (PyTorch Lightning)\n",
    "class SentimentClassificationTask(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=5e-5):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "# 모델 학습 실행\n",
    "task = SentimentClassificationTask(model)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,  \n",
    "    accelerator=\"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[pl.callbacks.EarlyStopping(monitor=\"train_loss\", patience=3)]\n",
    ")\n",
    "# 모델 성능 평가 함수\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"모델 정확도: {acc * 100:.2f}%\")\n",
    "\n",
    "# 모델 평가 실행\n",
    "print(\"테스트 데이터셋 평가 중...\")\n",
    "evaluate_model(task.model, test_dataloader)\n",
    "\n",
    "# 예제 문장 감정 분석 함수\n",
    "def predict_sentiment(model, text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    label_map = {0: \"부정 😡\", 1: \"긍정 😊\"}\n",
    "    print(f\"입력 문장: {text}\")\n",
    "    print(f\"예측 결과: {label_map[pred_class]} (확률: {probs[0][pred_class] * 100:.2f}%)\\n\")\n",
    "\n",
    "# 예제 문장 감정 분석 실행\n",
    "sample_texts = [\n",
    "    \"이 영화는 정말 최고였어!\",\n",
    "    \"완전 최악이야, 시간 낭비했어.\",\n",
    "    \"그냥 그랬어. 별로 감흥이 없었어.\",\n",
    "    \"배우 연기가 너무 훌륭했어!\",\n",
    "    \"스토리가 너무 지루했어.\"\n",
    "]\n",
    "\n",
    "for text in sample_texts:\n",
    "    predict_sentiment(task.model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fc823-dec6-403b-a3f8-a930a6287f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
